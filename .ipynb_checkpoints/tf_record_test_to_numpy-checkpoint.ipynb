{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts TFRecord data into numpy. Feel free to modify based on your needs.\n",
    "\n",
    "Data is saved into pickle files. Every file contains a list of samples. # of the samples in a file can be set via config['num_samples_in_numpy_list']. \n",
    "\n",
    "Loading:\n",
    "data = pickle.load(open(<i>path-to-pkl-file</i>, 'rb'))\n",
    "\n",
    "Each sample is a dictionary with the following fields:\n",
    "<ol>\n",
    "  <li>'label': label of the gesture. A unique ID in {0,1,..,19},</li>\n",
    "  <li>'length': length of the gesture sequence, i.e., # of frames,</li>\n",
    "  <li>'depth': tensor of depth images (length, height, width, 1),</li>\n",
    "  <li>'skeleton': tensor of skeleton joints (length, 180),</li>\n",
    "  <li>'rgb': tensor of rgb images (length, height, width, 3),</li>\n",
    "  <li>'segmentation': tensor of segmentation masks (length, height, width, 3).</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "Note that samples have different number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_op(image_op, shape):\n",
    "    \"\"\"\n",
    "    Creates preprocessing operations that are going to be applied on a single frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"preprocessing\"):\n",
    "        # Reshape serialized image.\n",
    "        return tf.reshape(image_op, shape)\n",
    "\n",
    "def read_and_decode_sequence(filename_queue, config):\n",
    "    # Create a TFRecordReader.\n",
    "    readerOptions = tf.python_io.TFRecordOptions(compression_type=tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    reader = tf.TFRecordReader(options=readerOptions)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    # Read one sequence sample.\n",
    "    # The training and validation files contains the following fields:\n",
    "    # - label: label of the sequence which take values between 1 and 20.\n",
    "    # - length: length of the sequence, i.e., number of frames.\n",
    "    # - depth: sequence of depth images. [length x height x width x numChannels]\n",
    "    # - rgb: sequence of rgb images. [length x height x width x numChannels]\n",
    "    # - segmentation: sequence of segmentation maskes. [length x height x width x numChannels]\n",
    "    # - skeleton: sequence of flattened skeleton joint positions. [length x numJoints]\n",
    "    #\n",
    "    # The test files doesn't contain \"label\" field.\n",
    "    with tf.name_scope(\"TFRecordDecoding\"):\n",
    "        context_encoded, sequence_encoded = tf.parse_single_sequence_example(\n",
    "                serialized_example,\n",
    "                # \"label\" and \"lenght\" are encoded as context features. \n",
    "                context_features={\n",
    "                    \"label\": tf.FixedLenFeature([], dtype=tf.int64),\n",
    "                    \"length\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "                },\n",
    "                # \"depth\", \"rgb\", \"segmentation\", \"skeleton\" are encoded as sequence features.\n",
    "                sequence_features={\n",
    "                    \"depth\": tf.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "                    \"rgb\": tf.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "                    \"segmentation\": tf.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "                    \"skeleton\": tf.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "                })\n",
    "\n",
    "        # Fetch data fields.\n",
    "        seq_rgb = tf.decode_raw(sequence_encoded['rgb'], tf.uint8)\n",
    "        seq_depth = tf.decode_raw(sequence_encoded['depth'], tf.uint8)\n",
    "        seq_segmentation = tf.decode_raw(sequence_encoded['segmentation'], tf.uint8)\n",
    "        \n",
    "        # Output dimnesionality: [seq_len, height, width, numChannels]\n",
    "        # tf.map_fn applies the preprocessing function on every image in the sequence, i.e., frame.\n",
    "        seq_rgb = tf.map_fn(lambda x: preprocessing_op(x, (config['img_height'], config['img_width'], config['img_num_channels'])),\n",
    "                                elems=seq_rgb,\n",
    "                                dtype=tf.uint8,\n",
    "                                back_prop=False)\n",
    "        seq_depth = tf.map_fn(lambda x: preprocessing_op(x, (config['img_height'], config['img_width'], 1)),\n",
    "                                elems=seq_depth,\n",
    "                                dtype=tf.uint8,\n",
    "                                back_prop=False)\n",
    "        \n",
    "        seq_segmentation = tf.map_fn(lambda x: preprocessing_op(x, (config['img_height'], config['img_width'], config['img_num_channels'])),\n",
    "                                elems=seq_segmentation,\n",
    "                                dtype=tf.uint8,\n",
    "                                back_prop=False)\n",
    "        \n",
    "        seq_label = context_encoded['label']\n",
    "        seq_len = tf.to_int32(context_encoded['length'])\n",
    "        \n",
    "        #[batch_size, seq_len, num_skeleton_joints]\n",
    "        seq_skeleton = tf.decode_raw(sequence_encoded['skeleton'], tf.float32)\n",
    "    \n",
    "        return [seq_rgb, seq_depth, seq_segmentation, seq_skeleton, seq_label, seq_len]\n",
    "    \n",
    "def input_pipeline(filenames, config):\n",
    "    with tf.name_scope(\"input_pipeline\"):\n",
    "        # Create a queue of TFRecord input files.\n",
    "        filename_queue = tf.train.string_input_producer(filenames, num_epochs=config['num_epochs'], shuffle=False)\n",
    "        # Read the data from TFRecord files, decode and create a list of data samples by using threads.\n",
    "        sample_list = [read_and_decode_sequence(filename_queue, config) for _ in range(config['ip_num_read_threads'])]\n",
    "        # Create batches.\n",
    "        batch_rgb, batch_depth, batch_segmentation,batch_skeleton, \\\n",
    "                    batch_labels, batch_lens = tf.train.batch_join(sample_list,\n",
    "                                                                    batch_size=config['batch_size'],\n",
    "                                                                    capacity=config['ip_queue_capacity'],\n",
    "                                                                    enqueue_many=False,\n",
    "                                                                    dynamic_pad=True,\n",
    "                                                                    allow_smaller_final_batch=True,\n",
    "                                                                    name=\"batch_join_and_pad\")\n",
    "\n",
    "        return batch_rgb, batch_depth, batch_segmentation, batch_skeleton, batch_labels, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, NewRandomAccessFile failed to Create/Open: /test/dataTest_1.tfrecords : Das System kann den angegebenen Pfad nicht finden.\r\n",
      "\n",
      "\t [[Node: input_pipeline/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline/TFRecordReaderV2, input_pipeline/input_producer)]]\n",
      "\t [[Node: input_pipeline/TFRecordDecoding/map_1/while/TensorArrayWrite/TensorArrayWriteV3/_91 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_282_input_pipeline/TFRecordDecoding/map_1/while/TensorArrayWrite/TensorArrayWriteV3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](^_cloopinput_pipeline/TFRecordDecoding/map_1/while/preprocessing/Reshape/_32)]]\n",
      "\n",
      "Caused by op 'input_pipeline/ReaderReadV2', defined at:\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-354856f0b5a5>\", line 26, in <module>\n",
      "    rgb_op, depth_op, segmentation_op, skeleton_op, label_op, seq_len_op = input_pipeline(filenames, config)\n",
      "  File \"<ipython-input-2-be2aebc4a001>\", line 76, in input_pipeline\n",
      "    sample_list = [read_and_decode_sequence(filename_queue, config) for _ in range(config['ip_num_read_threads'])]\n",
      "  File \"<ipython-input-2-be2aebc4a001>\", line 76, in <listcomp>\n",
      "    sample_list = [read_and_decode_sequence(filename_queue, config) for _ in range(config['ip_num_read_threads'])]\n",
      "  File \"<ipython-input-2-be2aebc4a001>\", line 14, in read_and_decode_sequence\n",
      "    _, serialized_example = reader.read(filename_queue)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py\", line 191, in read\n",
      "    return gen_io_ops._reader_read_v2(self._reader_ref, queue_ref, name=name)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 410, in _reader_read_v2\n",
      "    queue_handle=queue_handle, name=name)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 763, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2327, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"C:\\Users\\Andres\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1226, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "NotFoundError (see above for traceback): NewRandomAccessFile failed to Create/Open: /test/dataTest_1.tfrecords : Das System kann den angegebenen Pfad nicht finden.\r\n",
      "\n",
      "\t [[Node: input_pipeline/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline/TFRecordReaderV2, input_pipeline/input_producer)]]\n",
      "\t [[Node: input_pipeline/TFRecordDecoding/map_1/while/TensorArrayWrite/TensorArrayWriteV3/_91 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_282_input_pipeline/TFRecordDecoding/map_1/while/TensorArrayWrite/TensorArrayWriteV3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](^_cloopinput_pipeline/TFRecordDecoding/map_1/while/preprocessing/Reshape/_32)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "# TODO: You can change these fields.\n",
    "config['input_dir'] = \"/test/\" # Directory of the tfrecords.\n",
    "config['input_file_format'] = \"dataTest_%d.tfrecords\" # File naming\n",
    "config['input_file_ids'] = list(range(1,16)) # File IDs to be used for training.\n",
    "\n",
    "config['num_samples_in_numpy_list'] = 100 # Put 100 samples in a pickle data file. You can put everything in a single file as well.\n",
    "config['output_dir'] = config['input_dir']\n",
    "config['output_file_format'] = config['input_file_format'].split(\".\")[0]+\".pkl\"\n",
    "config['output_file_start_id'] = 1\n",
    "\n",
    "# Keep these fields fixed.\n",
    "config['img_height'] = 80\n",
    "config['img_width'] = 80\n",
    "config['img_num_channels'] = 3\n",
    "config['num_epochs'] = 1\n",
    "config['batch_size'] = 1\n",
    "# Capacity of the queue which contains the samples read by data readers.\n",
    "# Make sure that it has enough capacity.\n",
    "config['ip_queue_capacity'] = config['batch_size']*10  \n",
    "config['ip_num_read_threads'] = 1\n",
    "# Create a list of TFRecord input files.\n",
    "filenames = [os.path.join(config['input_dir'], config['input_file_format'] % i) for i in config['input_file_ids']]\n",
    "\n",
    "# Create data loading operators. This will be represented as a node in the computational graph.\n",
    "rgb_op, depth_op, segmentation_op, skeleton_op, label_op, seq_len_op = input_pipeline(filenames, config)\n",
    "\n",
    "# Create tensorflow session and initialize the variables (if any).\n",
    "sess = tf.Session()\n",
    "init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "sess.run(init_op)\n",
    "# Create threads to prefetch the data.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "np_file_id = config['output_file_start_id']\n",
    "output_list = []\n",
    "num_samples_read = 0\n",
    "try:\n",
    "    while not coord.should_stop():\n",
    "        rgb, depth, segmentation, skeleton, label, seq_len = sess.run([rgb_op, depth_op, segmentation_op, skeleton_op, label_op, seq_len_op])\n",
    "        num_samples_read += 1\n",
    "        data_sample = {}\n",
    "        data_sample['rgb'] = rgb[0] # Data is in batch format. Get rid of the first dimension.\n",
    "        data_sample['depth'] = depth[0]\n",
    "        data_sample['segmentation'] = segmentation[0]\n",
    "        data_sample['skeleton'] = skeleton[0]\n",
    "        data_sample['label'] = label[0]\n",
    "        data_sample['length'] = seq_len[0]\n",
    "        output_list.append(data_sample)\n",
    "        \n",
    "        if num_samples_read%config['num_samples_in_numpy_list'] == 0:\n",
    "            pickle.dump(output_list, open(os.path.join(config['output_dir'], config['output_file_format'] % np_file_id), 'wb'))\n",
    "            np_file_id += 1\n",
    "            output_list = []\n",
    "        \n",
    "except tf.errors.OutOfRangeError:\n",
    "    # Save last run.\n",
    "    if len(output_list) > 0:\n",
    "        pickle.dump(output_list, open(os.path.join(config['output_dir'], config['output_file_format'] % np_file_id), 'wb'))\n",
    "        output_list = []\n",
    "    print('Done.')\n",
    "finally:\n",
    "    # When done, ask the threads to stop.\n",
    "    coord.request_stop()\n",
    "\n",
    "# Wait for threads to finish.\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
